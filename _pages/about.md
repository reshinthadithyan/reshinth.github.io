---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---     
This is Reshinth Adithyan. This is Reshinth Adithyan, you can call me Reshinth. I am a Researcher/Research Engineer working in the intersection of <b>Machine Learning for Code Representation Learning for Developer Productivity and Static Analysis</b>. I started liking the process of writing a parser recently. As of 2022, I am focussed on Research of Neural Program Synthesis with DSLs at [Saama Research Lab](https://www.saama.com/category/saama-research/) and spending my free time at [Code.AI](https://code.ai) which is now under [Carper.AI](https://carper.ai/) thinking about Machine Learning applied on code.

Projects with Code Representation Learning
======
- <b><a href="https://github.com/CodedotAl/gpt-code-clippy" target="_blank">GPT-CODE-CLIPPY</a></b>
          Was part of the core team in buiding the open source GitHub CoPilot during the huggingface flax/jax sprint.
- <b><a href="https://huggingface.co/spaces/reshinthadith/code-representation-learning" target="_blank"> Code Representation Learning</a></b>is a collective of a Machine Learning on Code tasks, which are ready to showcase using HuggingFace Spaces.
- <b><a href="https://huggingface.co/reshinthadith/codet5-type-inference" target="_blank"> Type Inference using AutoRegressive Pre-Trained Transformers</a></b> A research project on Finetuning the codeT5 Model to infer the type of identifier in a given code snippet.
- <b><a href="https://github.com/reshinthadithyan/flashfill-program-synthesis" target="_blank"> Flash Fill Program Synthesis</a></b> Interpreted IO based program synthesis using Pre-Trained Transformers.
## Have a look at my Research Proposal
<a href="files/intrinsic_eval_proposal.pdf" target="_blank">Intrinsic Evaluation for Models trained on Code</a> Examining how well models trained with CausalLM objective, knows the context of the code.

Research Interests
======
- Code Representation Learning
- Parsers and Compilers
- Geometric Representation Learning in DFG(s)/CFG(s)
- Naturalness in Code
- Neural Program Synthesis
- Domain Specific Language Engineering
- Human Computer Interaction via Compilers
- <strong><a href = "https://openprocessing.org/user/267866?view=sketches" target="_blank"> Creative Coding.</strong></li></a>

Tools
=====
<li><strong>Languages :</strong> python, javascript, haskell, rust </li>
<li><strong>Deep Learning Tools :</strong> pytorch, jax, jraph, tensorflow, keras, huggingface Transformers, Pytorch Geometric. </li>
<li><strong>Parser Generators :</strong>jison, python lex-yacc, antlr</li>
